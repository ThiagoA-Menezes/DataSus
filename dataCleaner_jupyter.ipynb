{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validando a URL do datasus\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, f\"P:/Python - Projetos/lib/\")\n",
    "\n",
    "import dttools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lib importada para fazer o processamento paralelo.\n",
    "from multiprocessing import Pool \n",
    "\n",
    "def get_data_uf_ano_mes(uf ,ano, mes):\n",
    "    url = f\"ftp://ftp.datasus.gov.br/dissemin/publicos/SIHSUS/200801_/Dados/RD{uf}{ano}{mes}.dbc\"\n",
    "\n",
    "    file = f\"P:/Python - Projetos/Datasus/rd/dbc/RD{uf}{ano}{mes}.dbc\"\n",
    "\n",
    "    resp = urllib.request.urlretrieve(url, file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pega as datas e padroniza\n",
    "def get_data_uf(ufs, datas):\n",
    "    for i in tqdm(datas):\n",
    "        ano, mes, dia = i.split(\"-\")\n",
    "        ano = ano [-2:]\n",
    "        get_data_uf_ano_mes(ufs, ano, mes)\n",
    "\n",
    "# Lista de estados Brasileiros\n",
    "ufs  = [\"AC\", \"AL\", \"AP\", \"AM\", \"BA\", \n",
    "        \"CE\", \"DF\", \"ES\", \"GO\", \"MA\", \n",
    "        \"MT\", \"MS\", \"MG\", \"PA\", \"PB\", \n",
    "        \"PR\", \"PE\", \"PI\", \"RJ\", \"RN\", \n",
    "        \"RS\", \"RO\", \"RR\", \"SC\", \"SP\", \n",
    "        \"SE\", \"TO\"]\n",
    "\n",
    "# Lista de datas que serão baixadas do site do Datasus.\n",
    "datas = ['2023-01-01', '2023-02-01']\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AC', 'AL', 'AP', 'AM', 'BA', 'CE', 'DF', 'ES', 'GO', 'MA', 'MT', 'MS', 'MG', 'PA', 'PB', 'PR', 'PE', 'PI', 'RJ', 'RN', 'RS', 'RO', 'RR', 'SC', 'SP', 'SE', 'TO']\n"
     ]
    }
   ],
   "source": [
    "#for uf in ufs:\n",
    "#    get_data_uf(ufs, datas)\n",
    "\n",
    "#data = [ (\"AC\", ['2023-01-01', '2023-02-01']),\n",
    "#         (\"AM\", ['2023-01-01', '2023-02-01']),\n",
    "#         (\"AP\", ['2023-01-01', '2023-02-01']),\n",
    "#          (\"DF\", ['2023-01-01', '2023-02-01']), ]\n",
    "# \n",
    "with Pool(8) as pool:\n",
    "    print(ufs)\n",
    "    pool.starmap(get_data_uf,datas)\n",
    "#\n",
    "#import os\n",
    "#\n",
    "#os.listdir(\"P:/Python - Projetos/Datasus/rd/dbc/\")\n",
    "#\n",
    "# Criar a pasta na pasta\n",
    "#os.mkdir(\"P:/Python - Projetos/Datasus/rd/dbc\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Aqui iremos colocar o array que vai fazer a baixa dos arquivos em paralelo.\n",
    "\n",
    "#to_download = [(uf,datas) for uf in ufs]\n",
    "\n",
    "# Inserindo a função que vai fazer o processamento paralelo.\n",
    "\n",
    "#with Pool(2) as pool:\n",
    "#    pool.starmap(get_data_uf, to_download)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
